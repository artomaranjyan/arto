---
layout: talks
permalink: /talks/
title: Talks
description: 
nav: true
nav_order: 5
---

### 2024 Talks and Poster Presentations

<ol start="11" reversed>
  <li><strong>MindFlayer: Efficient Asynchronous Parallel SGD in the Presence of Heterogeneous and Random Worker Compute Times</strong><br>
      <em>Talk</em> @ <a href="https://gmg70.com/"><em>Analysis, PDEs and Applications</em></a> <a href="https://gmg70.com/downloads/ConferenceAbstracts.pdf#page=19">[abstract]</a><br>
      Yerevan State University, Yerevan, Armenia, July 6, 2024
  </li>
  <li><strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong><br>
      <em>Poster presentation</em> @ <a href="https://cemse.kaust.edu.sa/events/event/snsl-workshop-2024"><em>Stochastic Numerics and Statistical Learning: Theory and Applications Workshop 2024</em></a> <a href="https://artomaranjyan.github.io/assets/pdf/GradSkip_Rising_Stars.pdf">[poster]</a> <br>
      KAUST, Thuwal, Saudi Arabia, May 27, 2024
  </li>
  <li><strong>MindFlayer: Efficient Asynchronous Parallel SGD in the Presence of Heterogeneous and Random Worker Compute Times</strong><br>
      <em>Guest lecture</em> @ CS 331, Stochastic Gradient Descent Methods<br>
      KAUST, Thuwal, Saudi Arabia, May 5, 2024
  </li>
  <li><strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong><br>
      <em>Poster presentation</em> @ <a href="https://groups.oist.jp/mlss"><em>The Machine Learning Summer School in Okinawa 2024</em></a> <a href="https://artomaranjyan.github.io/assets/pdf/GradSkip_MLSS_Okinawa.pdf">[poster]</a> <br>
      Okinawa Institute of Science and Technology (OIST), Okinawa, Japan, March 13, 2024
  </li>
  <li><strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong><br>
      <em>Poster presentation</em> @ <a href="https://cemse.kaust.edu.sa/ai/aii-symp-2024"><em>KAUST Rising Stars in AI Symposium 2024</em></a> <a href="https://artomaranjyan.github.io/assets/pdf/GradSkip_Rising_Stars.pdf">[poster]</a><br>
      KAUST, Thuwal, Saudi Arabia, February 21, 2024
  </li>
</ol>

### 2023 Talks and Poster Presentations

<ol start="6" reversed>
  <li><strong>Differentially Private Coordinate Descent for Composite Empirical Risk Minimization</strong><br>
      <em>Talk</em> @ Group Seminar<br>
      KAUST, Thuwal, Saudi Arabia, November 16, 2023
  </li>
  <li><strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong><br>
      <em>Talk</em> @ <a href="https://warwick.ac.uk/fac/sci/statistics/news/algorithms-seminars/#:~:text=06/10-,Artavazd%20Maranjyan,-Link%20opens%20in"><em>Algorithms & Computationally Intensive Inference seminars</em></a> <a href="https://warwick.ac.uk/fac/sci/statistics/news/algorithms-seminars/slides_2023_10_06_arto_maranjyan_gradskip.pdf">[slides]</a><br>
      University of Warwick, Coventry, England, October 6, 2023
  </li>
  <li><strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong><br>
      <em>Talk</em> @ <a href="http://mathconf.sci.am/index.html"><em>Mathematics in Armenia: Advances and Perspectives</em></a> <a href="http://mathconf.sci.am/MiA2023AbstractsBook.pdf#page=60">[abstract]</a><br>
      Yerevan State University, Yerevan, Armenia, July 5, 2023
  </li>
  <li><strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong><br>
      <em>Talk</em> @ <a href="https://groups.google.com/g/ml-reading-group-yerevan/c/F_1OGqeFImY/m/BGDIqZAWBQAJ"><em>Machine Learning Reading Group Yerevan</em></a> <a href="https://www.youtube.com/watch?v=w9iHPgE82oo">[video (Armenian)]</a><br>
      Yerevan State University, Yerevan, Armenia, March 10, 2023
  </li>
</ol>

### 2022 Talks and Poster Presentations

<ol start="2" reversed>
  <li><strong>GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</strong><br>
      <em>Talk</em> @ <a href="https://sites.google.com/view/one-world-seminar-series-flow/archive/2022?authuser=0#h.99nho9x1b8ju"><em>Federated Learning One World Seminar (FLOW)</em></a> <a href="https://youtu.be/WWhY5tO-FiM">[video]</a><br>
      Online, December 7, 2022
  </li>
  <li><strong>ProxSkip: Yes! Local Gradient Steps Provably Lead to Communication Acceleration! Finally!</strong><br>
      <em>Talk</em> @ <a href="https://groups.google.com/g/ml-reading-group-yerevan/c/-TZmYEWATuI"><em>Machine Learning Reading Group Yerevan</em></a><br>
      Yerevan State University, Yerevan, Armenia, April 10, 2022
  </li>
</ol>
